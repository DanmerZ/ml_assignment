{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML assignment\n",
    "\n",
    "**Authors:**\n",
    " - Oleh Pomazan *oleh.pomazan@ue-germany.de*\n",
    "\n",
    " Original paper link: https://www.sciencedirect.com/science/article/pii/S2352484720313007#b13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from features import (RANDOM_STATE, read_features_from_csv)\n",
    "\n",
    "# features = read_features_from_csv()\n",
    "train_frame, test_frame, x_train, x_test, y_train, y_test = read_features_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "      <th>class_id</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8450</th>\n",
       "      <td>8450</td>\n",
       "      <td>input/audio/fold1/193698-2-0-58.wav</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>2</td>\n",
       "      <td>[-319.29752, 102.58311, -49.749527, 7.117446, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8585</th>\n",
       "      <td>8585</td>\n",
       "      <td>input/audio/fold1/118279-8-0-4.wav</td>\n",
       "      <td>siren</td>\n",
       "      <td>8</td>\n",
       "      <td>[-279.48712, 112.4627, -27.210625, 27.530556, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>2404</td>\n",
       "      <td>input/audio/fold7/83488-1-0-0.wav</td>\n",
       "      <td>car_horn</td>\n",
       "      <td>1</td>\n",
       "      <td>[-176.89964, -65.4562, -2.5445695, 52.369923, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>4477</td>\n",
       "      <td>input/audio/fold5/196062-2-0-0.wav</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>2</td>\n",
       "      <td>[-281.53714, 43.722984, -21.65799, 24.144136, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>6173</td>\n",
       "      <td>input/audio/fold2/102871-8-0-13.wav</td>\n",
       "      <td>siren</td>\n",
       "      <td>8</td>\n",
       "      <td>[-276.41293, 153.79091, -51.535614, -6.9765244...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>5734</td>\n",
       "      <td>input/audio/fold6/63724-0-0-9.wav</td>\n",
       "      <td>air_conditioner</td>\n",
       "      <td>0</td>\n",
       "      <td>[-353.99768, 120.82677, -25.244507, 34.66291, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>5191</td>\n",
       "      <td>input/audio/fold5/178686-0-0-53.wav</td>\n",
       "      <td>air_conditioner</td>\n",
       "      <td>0</td>\n",
       "      <td>[-377.1148, 169.02785, -28.958954, 31.370935, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>5390</td>\n",
       "      <td>input/audio/fold6/39852-5-0-1.wav</td>\n",
       "      <td>engine_idling</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.2182836, 156.47552, -29.636814, 39.782234,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>860</td>\n",
       "      <td>input/audio/fold4/24347-8-0-51.wav</td>\n",
       "      <td>siren</td>\n",
       "      <td>8</td>\n",
       "      <td>[-128.50357, 166.96239, -68.697365, -8.287582,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>7270</td>\n",
       "      <td>input/audio/fold8/113202-5-0-26.wav</td>\n",
       "      <td>engine_idling</td>\n",
       "      <td>5</td>\n",
       "      <td>[-300.0753, 151.16785, 27.143927, 27.602556, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6985 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                 path             class  \\\n",
       "8450        8450  input/audio/fold1/193698-2-0-58.wav  children_playing   \n",
       "8585        8585   input/audio/fold1/118279-8-0-4.wav             siren   \n",
       "2404        2404    input/audio/fold7/83488-1-0-0.wav          car_horn   \n",
       "4477        4477   input/audio/fold5/196062-2-0-0.wav  children_playing   \n",
       "6173        6173  input/audio/fold2/102871-8-0-13.wav             siren   \n",
       "...          ...                                  ...               ...   \n",
       "5734        5734    input/audio/fold6/63724-0-0-9.wav   air_conditioner   \n",
       "5191        5191  input/audio/fold5/178686-0-0-53.wav   air_conditioner   \n",
       "5390        5390    input/audio/fold6/39852-5-0-1.wav     engine_idling   \n",
       "860          860   input/audio/fold4/24347-8-0-51.wav             siren   \n",
       "7270        7270  input/audio/fold8/113202-5-0-26.wav     engine_idling   \n",
       "\n",
       "      class_id                                           features  \n",
       "8450         2  [-319.29752, 102.58311, -49.749527, 7.117446, ...  \n",
       "8585         8  [-279.48712, 112.4627, -27.210625, 27.530556, ...  \n",
       "2404         1  [-176.89964, -65.4562, -2.5445695, 52.369923, ...  \n",
       "4477         2  [-281.53714, 43.722984, -21.65799, 24.144136, ...  \n",
       "6173         8  [-276.41293, 153.79091, -51.535614, -6.9765244...  \n",
       "...        ...                                                ...  \n",
       "5734         0  [-353.99768, 120.82677, -25.244507, 34.66291, ...  \n",
       "5191         0  [-377.1148, 169.02785, -28.958954, 31.370935, ...  \n",
       "5390         5  [-0.2182836, 156.47552, -29.636814, 39.782234,...  \n",
       "860          8  [-128.50357, 166.96239, -68.697365, -8.287582,...  \n",
       "7270         5  [-300.0753, 151.16785, 27.143927, 27.602556, 7...  \n",
       "\n",
       "[6985 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "      <th>class_id</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>6770</td>\n",
       "      <td>input/audio/fold2/203128-3-6-0.wav</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>3</td>\n",
       "      <td>[-245.69205, 104.1259, -40.40444, -33.80086, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>3534</td>\n",
       "      <td>input/audio/fold9/101729-0-0-23.wav</td>\n",
       "      <td>air_conditioner</td>\n",
       "      <td>0</td>\n",
       "      <td>[-247.12012, 43.795162, 33.967854, 24.374525, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8556</th>\n",
       "      <td>8556</td>\n",
       "      <td>input/audio/fold1/177621-0-0-0.wav</td>\n",
       "      <td>air_conditioner</td>\n",
       "      <td>0</td>\n",
       "      <td>[-223.05162, 114.45852, 29.96794, 1.3511316, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>7870</td>\n",
       "      <td>input/audio/fold1/157867-8-0-22.wav</td>\n",
       "      <td>siren</td>\n",
       "      <td>8</td>\n",
       "      <td>[-308.7529, 60.80618, -32.960495, -8.78716, -5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>1226</td>\n",
       "      <td>input/audio/fold3/176783-3-0-3.wav</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>3</td>\n",
       "      <td>[-487.41376, 134.71155, -57.171463, 28.707848,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>input/audio/fold4/159752-8-2-1.wav</td>\n",
       "      <td>siren</td>\n",
       "      <td>8</td>\n",
       "      <td>[-411.13675, 218.53635, 5.624176, 17.057047, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>1794</td>\n",
       "      <td>input/audio/fold3/199769-1-0-0.wav</td>\n",
       "      <td>car_horn</td>\n",
       "      <td>1</td>\n",
       "      <td>[-212.01712, 116.12175, -7.3977575, 20.432745,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>3202</td>\n",
       "      <td>input/audio/fold9/62567-5-0-2.wav</td>\n",
       "      <td>engine_idling</td>\n",
       "      <td>5</td>\n",
       "      <td>[-297.126, 174.29768, 38.8224, 32.795914, 22.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>2221</td>\n",
       "      <td>input/audio/fold7/84143-2-0-7.wav</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>2</td>\n",
       "      <td>[-146.49277, 130.51808, -46.111217, 12.337456,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>5766</td>\n",
       "      <td>input/audio/fold6/107842-4-2-3.wav</td>\n",
       "      <td>drilling</td>\n",
       "      <td>4</td>\n",
       "      <td>[-26.412651, -10.635736, 7.225783, 6.469247, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1747 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                 path             class  \\\n",
       "6770        6770   input/audio/fold2/203128-3-6-0.wav          dog_bark   \n",
       "3534        3534  input/audio/fold9/101729-0-0-23.wav   air_conditioner   \n",
       "8556        8556   input/audio/fold1/177621-0-0-0.wav   air_conditioner   \n",
       "7870        7870  input/audio/fold1/157867-8-0-22.wav             siren   \n",
       "1226        1226   input/audio/fold3/176783-3-0-3.wav          dog_bark   \n",
       "...          ...                                  ...               ...   \n",
       "73            73   input/audio/fold4/159752-8-2-1.wav             siren   \n",
       "1794        1794   input/audio/fold3/199769-1-0-0.wav          car_horn   \n",
       "3202        3202    input/audio/fold9/62567-5-0-2.wav     engine_idling   \n",
       "2221        2221    input/audio/fold7/84143-2-0-7.wav  children_playing   \n",
       "5766        5766   input/audio/fold6/107842-4-2-3.wav          drilling   \n",
       "\n",
       "      class_id                                           features  \n",
       "6770         3  [-245.69205, 104.1259, -40.40444, -33.80086, -...  \n",
       "3534         0  [-247.12012, 43.795162, 33.967854, 24.374525, ...  \n",
       "8556         0  [-223.05162, 114.45852, 29.96794, 1.3511316, 7...  \n",
       "7870         8  [-308.7529, 60.80618, -32.960495, -8.78716, -5...  \n",
       "1226         3  [-487.41376, 134.71155, -57.171463, 28.707848,...  \n",
       "...        ...                                                ...  \n",
       "73           8  [-411.13675, 218.53635, 5.624176, 17.057047, 2...  \n",
       "1794         1  [-212.01712, 116.12175, -7.3977575, 20.432745,...  \n",
       "3202         5  [-297.126, 174.29768, 38.8224, 32.795914, 22.1...  \n",
       "2221         2  [-146.49277, 130.51808, -46.111217, 12.337456,...  \n",
       "5766         4  [-26.412651, -10.635736, 7.225783, 6.469247, 9...  \n",
       "\n",
       "[1747 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape=(6985, 43)\n",
      "x_test.shape=(1747, 43)\n",
      "y_train.shape=(6985,)\n",
      "y_test.shape=(1747,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train.shape={x_train.shape}\")\n",
    "print(f\"x_test.shape={x_test.shape}\")\n",
    "\n",
    "print(f\"y_train.shape={y_train.shape}\")\n",
    "print(f\"y_test.shape={y_test.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-neighbors classifier from sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;chebyshev&#x27;, &#x27;cosine&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [3, 5, 7, 9, 11, 15],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;chebyshev&#x27;, &#x27;cosine&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [3, 5, 7, 9, 11, 15],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'metric': ['euclidean', 'chebyshev', 'cosine'],\n",
       "                         'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
       "                         'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'chebyshev', 'cosine']\n",
    "}\n",
    "\n",
    "model = GridSearchCV(KNeighborsClassifier(), grid_params, cv=5, n_jobs=-1)\n",
    "model.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'cosine', 'n_neighbors': 3, 'weights': 'distance'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.9484831139095592\n",
      "Confusion Matrix: \n",
      "[[214   3   1   0   1   1   1   0   0   1]\n",
      " [  0  79   1   0   0   1   0   0   0   1]\n",
      " [  0   1 190   3   1   0   0   0   0  10]\n",
      " [  0   0   4 166   1   0   2   0   1   3]\n",
      " [  0   0   1   2 201   0   1   3   1   1]\n",
      " [  0   0   4   0   0 199   0   0   0   0]\n",
      " [  0   1   2  14   0   0  64   0   0   0]\n",
      " [  0   1   0   0   5   1   0 179   0   3]\n",
      " [  0   0   0   4   0   0   0   0 179   1]\n",
      " [  0   1   1   1   2   1   1   1   0 186]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(f'Model Score: {model.score(x_test_scaled, y_test)}')\n",
    "\n",
    "y_predict = model.predict(x_test_scaled)\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_predict, y_test)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-neighbors classifier implementation based on Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_model.score = 0.8952489982827705\n",
      "Confusion Matrix: \n",
      "[[214   3   1   0   1   1   1   0   0   1]\n",
      " [  0  79   1   0   0   1   0   0   0   1]\n",
      " [  0   1 190   3   1   0   0   0   0  10]\n",
      " [  0   0   4 166   1   0   2   0   1   3]\n",
      " [  0   0   1   2 201   0   1   3   1   1]\n",
      " [  0   0   4   0   0 199   0   0   0   0]\n",
      " [  0   1   2  14   0   0  64   0   0   0]\n",
      " [  0   1   0   0   5   1   0 179   0   3]\n",
      " [  0   0   0   4   0   0   0   0 179   1]\n",
      " [  0   1   1   1   2   1   1   1   0 186]]\n"
     ]
    }
   ],
   "source": [
    "from knn import KNN\n",
    "\n",
    "np_model = KNN()\n",
    "np_model.fit(x_train_scaled, y_train)\n",
    "np_accuracy = np_model.score(x_test_scaled, y_test)\n",
    "y_predict = model.predict(x_test_scaled)\n",
    "print(f\"np_model.score = {np_accuracy}\")\n",
    "\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_predict, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNN(), n_jobs=-1,\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;chebyshev&#x27;, &#x27;cosine&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [3, 5],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNN(), n_jobs=-1,\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;chebyshev&#x27;, &#x27;cosine&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [3, 5],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNN</label><div class=\"sk-toggleable__content\"><pre>KNN()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNN</label><div class=\"sk-toggleable__content\"><pre>KNN()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNN(), n_jobs=-1,\n",
       "             param_grid={'metric': ['euclidean', 'chebyshev', 'cosine'],\n",
       "                         'n_neighbors': [3, 5],\n",
       "                         'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params = {\n",
    "    'n_neighbors': [3, 5], # narrow down search space due to time limitations\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'chebyshev', 'cosine']\n",
    "}\n",
    "\n",
    "model = GridSearchCV(KNN(), grid_params, cv=5, n_jobs=-1)\n",
    "model.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'cosine', 'n_neighbors': 3, 'weights': 'distance'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.9484831139095592\n",
      "Confusion Matrix: \n",
      "[[214   3   1   0   1   1   1   0   0   1]\n",
      " [  0  79   1   0   0   1   0   0   0   1]\n",
      " [  0   1 190   3   1   0   0   0   0  10]\n",
      " [  0   0   4 166   1   0   2   0   1   3]\n",
      " [  0   0   1   2 201   0   1   3   1   1]\n",
      " [  0   0   4   0   0 199   0   0   0   0]\n",
      " [  0   1   2  14   0   0  64   0   0   0]\n",
      " [  0   1   0   0   5   1   0 179   0   3]\n",
      " [  0   0   0   4   0   0   0   0 179   1]\n",
      " [  0   1   1   1   2   1   1   1   0 186]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Model Score: {model.score(x_test_scaled, y_test)}')\n",
    "\n",
    "y_predict = model.predict(x_test_scaled)\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_predict, y_test)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.7040641099026903\n",
      "Confusion Matrix: \n",
      "[[178   0  10   4   1   3   1   4   1  10]\n",
      " [  1  52   0   3   3   1   3   8   1   5]\n",
      " [  6   5 120  17   9   7   7   4   6  25]\n",
      " [  6   6  22 118   8   2   5   2  12  10]\n",
      " [  5   4   7   9 159   3   2  11   2  18]\n",
      " [  5   3   7   0   2 171   2   3   5  11]\n",
      " [  0   2   4  13   5   3  38   2   4   6]\n",
      " [  3   5   6   1  13   3   2 137   1   5]\n",
      " [  4   2   4   9   0   1   2   4 146   5]\n",
      " [  6   7  24  16  11   9   7   8   3 111]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "grid_params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_features\": (1, 3, 5, 10, 'sqrt', 'log2', None)\n",
    "}\n",
    "\n",
    "# tree_classifier = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "tree_classifier = GridSearchCV(DecisionTreeClassifier(random_state=RANDOM_STATE), grid_params, cv=5, n_jobs=-1)\n",
    "tree_classifier.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(f'Model Score: {tree_classifier.score(x_test_scaled, y_test)}')\n",
    "\n",
    "y_predict = tree_classifier.predict(x_test_scaled)\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_predict, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_features': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': 42,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_classifier.best_estimator_.get_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN approach\n",
    "\n",
    "Based on https://medium.com/@hasithsura/audio-classification-d37a82d6715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cfae394d8f8fd3aafad6adb6787ce5d059872fa6e0cd8be9539e55e00a423e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
